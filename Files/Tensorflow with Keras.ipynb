{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import gzip\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's start by getting familiar with the data we'll be using, the Fashion MNIST dataset. \n",
    "#This dataset contains 70,000 grayscale images of articles of clothing — 60,000 meant to be used for training and 10,000 meant for testing.\n",
    "#The images are square and contain 28 × 28 = 784 pixels, where each pixel is represented by a value between 0 and 255. \n",
    "#Each of these images is associated with a label, which is an integer between 0 and 9 that classifies the article of clothing. \n",
    "#The following dictionary helps us understand the clothing categories corresponding to these integer labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_map = {\n",
    "  0: 'T-Shirt',\n",
    "  1: 'Trouser',\n",
    "  2: 'Pullover',\n",
    "  3: 'Dress',\n",
    "  4: 'Coat',\n",
    "  5: 'Sandal',\n",
    "  6: 'Shirt',\n",
    "  7: 'Sneaker',\n",
    "  8: 'Bag',\n",
    "  9: 'Ankle Boot',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you're following this code but executing it outside of this Microsoft Learn sandbox notebook environment, you can load Fashion MNIST by calling the load_data() method of the Fashion MNIST dataset in the Keras API, as you can see in the commented out code below.\n",
    "#Keras provides an easy way to get not only Fashion MNIST, but many other popular datasets through tk.keras.datasets.\n",
    "#In this Learn sandbox notebook we already have the data locally, so we'll load it directly instead, and create four NumPy arrays containing the training and test data and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (training_images, training_labels), (test_images, test_labels) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "def read_images(path: str, image_size: int, num_items: int) -> np.ndarray:\n",
    "  with gzip.open(path, 'rb') as file:\n",
    "    data = np.frombuffer(file.read(), np.uint8, offset=16)\n",
    "    data = data.reshape(num_items, image_size, image_size)\n",
    "  return data\n",
    "\n",
    "def read_labels(path: str, num_items: int) -> np.ndarray:\n",
    "  with gzip.open(path, 'rb') as file:\n",
    "    data = np.frombuffer(file.read(num_items + 8), np.uint8, offset=8)\n",
    "    data = data.astype(np.int64)\n",
    "  return data\n",
    "\n",
    "image_size = 28\n",
    "num_train = 60000\n",
    "num_test = 10000\n",
    "\n",
    "training_images = read_images('data/FashionMNIST/raw/train-images-idx3-ubyte.gz', image_size, num_train)\n",
    "test_images = read_images('data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz', image_size, num_test)\n",
    "training_labels = read_labels('data/FashionMNIST/raw/train-labels-idx1-ubyte.gz', num_train)\n",
    "test_labels = read_labels('data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz', num_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now that we have the data, we can display a sampling of images and corresponding labels from the training data, to get a feel for the data we'll be working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols = 3\n",
    "rows = 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "  sample_idx = random.randint(0, len(training_images))\n",
    "  image = training_images[sample_idx]\n",
    "  label = training_labels[sample_idx]\n",
    "  figure.add_subplot(rows, cols, i)\n",
    "  plt.title(labels_map[label])\n",
    "  plt.axis('off')\n",
    "  plt.imshow(image.squeeze(), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspect the first label in the training data:\n",
    "\n",
    "training_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
